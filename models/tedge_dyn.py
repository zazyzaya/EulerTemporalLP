from copy import deepcopy

import torch 
from torch import nn 
from torch.autograd import Variable
from torch.distributed import rpc
from torch.nn.parallel import DistributedDataParallel as DDP

from .embedders import GCN 
from .static import StaticRecurrent, StaticEncoder
from .tedge import TEdgeAnoms, TEdgeDecoder, TEdgeRecurrent
from .utils import _remote_method_async


# From Ramesh's paper, this is f(u,v,N(u))
class TEdgeAnomsDynamic(TEdgeAnoms):
    def inner_forward(self, x, ei):
        # Loss is a little more complicated now, so we calculate it sepearately
        return self.H(x,ei)
    
    def inner_loss(self, H, ei):
        '''
        Assumes H is aligned w ei s.t. H[0] represents embeddings from
        timestep 0 and ei[0] represents edges at timestep 1
        '''
        dists = self.W(H)
        return self.ce_loss(
            dists[ei[0]],
            ei[1]
        )

    def loss_fn(self, H, ei, no_grad):
        if no_grad:
            with torch.no_grad():
                return self.inner_loss(H, ei)
        return self.inner_loss(H, ei)


def dyn_tedge_rref(loader, kwargs, h_dim, z_dim, head=False):
    return TEdgeEncoderDynamic(
        GCN(loader, kwargs, h_dim, z_dim), 
        head, TEdgeAnomsDynamic, z_dim 
    )

class TEdgeDynDecoder(TEdgeDecoder):
    '''
    DDP wrapper for decoder class w added methods for dynamic version
    '''
    def loss_fn(self, H, ei, no_grad):
        return self.module.loss_fn(H, ei, no_grad)

class TEdgeEncoderDynamic(StaticEncoder):
    def __init__(self, module, head, decoder_constructor, z_dim, **kwargs):
        super().__init__(module, **kwargs)
        
        self.is_head = 1 if head else 0
        if self.is_head:
            print("%s is head" % rpc.get_worker_info().name)

        # Cleaner naming convention
        self.encoder = self.module 
        
        # Need to wrap in a DDP to coordinate params again. Luckilly this time it's pretty
        # simple to do. We just have to add one additional method to the baseline DDP class
        self.decoder = TEdgeDynDecoder(
            decoder_constructor(
                z_dim//2, 
                self.module.data.num_nodes, 
                5
            )
        )
        
    def parameters(self, recurse: bool = True):
        '''
        Exclude decoder params as those are trained seperately
        '''
        return self.encoder.parameters(recurse=recurse)

    def decoder_parameters(self, recurse: bool=True):
        '''
        Exclude encoder params
        ''' 
        return self.decoder.parameters(recurse=recurse)



    def anom_forward(self, zs, partition, no_grad):
        '''
        Generates H embeds for anom detection
        '''
        H = []
        
        for i in range(self.encoder.data.T):
            ei = self.encoder.data.ei_masked(partition, i)

            if ei.size(1):
                h = self.decoder(zs[i], ei, no_grad=no_grad)
                H.append(h)
            
            # This SHOULD only happen during val so this hopefully won't ruin 
            # anything.. In any case, there are implied self-loops so this is 
            # H entry is sound
            else:
                H.append(zs[i])

        return torch.stack(H)


    def decode_all(self, H, unsqueeze=True):
        '''
        Given node embeddings, return edge likelihoods for 
        all subgraphs held by this model
        
        For dynamic model, assume we are given embeddings 
        for timesteps -1 to N-1 (where Z_{-1} is a dummy value
        to be ignored if this is worker 0) with which to predict
        E_1 to E_N

        zs : torch.Tensor
            A T x d x N tensor of node embeddings generated by the models, 
            it is safe to assume z[n] are the embeddings for nodes in the 
            snapshot held by this model's TGraph at timestep n
        '''
        preds, ys, cnts = [], [], []
        for i in range(self.is_head, self.encoder.data.T):
            preds.append(
                self.decoder.score(
                    H[i],
                    self.encoder.data.eis[i]
                )
            )

            ys.append(self.encoder.data.ys[i])
            cnts.append(self.encoder.data.cnt[i])

        return preds, ys, cnts

    def score_edges(self, H, partition, nratio):
        n = self.encoder.data.get_negative_edges(partition, nratio)

        p_scores = []
        n_scores = []

        for i in range(self.is_head, self.module.data.T):
            p = self.encoder.data.ei_masked(partition, i)
            if p.size(1) == 0:
                continue

            p_scores.append(self.decoder.score(H[i], p))
            n_scores.append(self.decoder.score(H[i], n[i]))

        p_scores = torch.cat(p_scores, dim=0)
        n_scores = torch.cat(n_scores, dim=0)

        return p_scores, n_scores

    def anom_loss(self, H, partition, no_grad):
        '''
        Want the anom detector to predict next timestep (ie H[0] predicts ei[1])
        Thus, we assume the H embeds are offset already, and if head, H[0] is a dummy value
        '''
        loss = torch.zeros(1)
        for i in range(len(H)):
            ps = self.encoder.data.ei_masked(partition, i)
            
            if not ps.size(1):
                continue 

            if self.is_head:
                if i > 0:
                    loss += self.decoder.loss_fn(H[i], ps, no_grad)
            else:
                loss += self.decoder.loss_fn(H[i], ps, no_grad)

        if len(H)-self.is_head:
            return loss.true_divide(len(H)-self.is_head)

        return torch.zeros(1)


class TEdgeRecurrentDynamic(TEdgeRecurrent):
    def anom_forward(self, mask_enum, zs, no_grad=False):
        # Train the anomaly detector on the output of the embedder at the same time 
        # note the Variable though; loss here won't backprop into the GNN/RNN
        self.decoding = True

        futs = []
        start = 0

        zs = Variable(zs)
        for i in range(self.num_workers):
            end = start + self.len_from_each[i]
            futs.append(
                _remote_method_async(
                    TEdgeEncoderDynamic.anom_forward,
                    self.gcns[i],
                    zs[start : end], 
                    mask_enum,
                    no_grad
                )
            )
            start = end 

        H = [f.wait() for f in futs]
        H = torch.cat(H, dim=0)
        
        # Align H[0] to predict G[1], and trim off extra value at the end
        H = torch.cat([
            torch.zeros(H[0].size()).unsqueeze(0),
            H[:-1]
        ])

        # Finally, split into parts for calculating loss/scores later
        self.H = []
        start = 0
        for i in range(self.num_workers):
            end = start + self.len_from_each[i]
            self.H.append(H[start:end])
            start = end 

        # Then calculate loss     
        futs = [
            _remote_method_async(
                TEdgeEncoderDynamic.anom_loss,
                self.gcns[i],
                self.H[i], 
                mask_enum,
                no_grad
            )
            for i in range(self.num_workers)
        ]

        return [f.wait() for f in futs]


    def score_all(self, zs, unsqueeze=False):
        '''
        Has the distributed models score and label all of their edges
        Sends workers embeddings such that H[n] is used to reconstruct graph at 
        snapshot n

        H : torch.Tensor 
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        '''
        futs = [
            _remote_method_async(
                TEdgeEncoderDynamic.decode_all,
                self.gcns[i],
                self.H[i],
                unsqueeze=unsqueeze
            )
            for i in range(self.num_workers) 
        ]

        obj = [f.wait() for f in futs]
        scores, ys, cnts = zip(*obj)
        
        # Compress into single list of snapshots
        scores = sum(scores, [])
        ys = sum(ys, [])
        cnts = sum(cnts, [])

        return scores, ys, cnts
        

    def score_edges(self, zs, partition, nratio=1):
        '''
        Gets edge scores from dist modules, and negative edges. 
        Sends workers embeddings such that zs[n] is used to reconstruct graph at 
        snapshot n

        zs : torch.Tensor 
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        partition : int
            enum representing train, validation, test sent to workers
        nratio : float
            The workers sample nratio * |E| negative edges for calculating loss
        '''
        if not self.decoding:
            print("Returning Static score")
            return super().score_edges(zs, partition, nratio)
    
        print("Returning dynamic TEdge score")
        futs = [
            _remote_method_async(
                TEdgeEncoderDynamic.score_edges,
                self.gcns[i],
                self.H[i], 
                partition, nratio
            )
        for i in range(self.num_workers) ]

        pos, neg = zip(*[f.wait() for f in futs])
        return torch.cat(pos, dim=0), torch.cat(neg, dim=0)
    